{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09194f8-3e2e-454e-b506-a253405cb5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import ants\n",
    "import iblatlas.atlas as atlas\n",
    "import json\n",
    "\n",
    "from aind_morphology_utils.utils import read_swc\n",
    "\n",
    "from extract_spikes import extract_spikes\n",
    "from extract_continuous import extract_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d618dc1-f872-4180-ba5c-47c89142c969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_swc_probe_data(filename):\n",
    "    S = read_swc(filename)\n",
    "    return pd.DataFrame(S.compartment_list)\n",
    "\n",
    "\n",
    "def create_slicer_fcsv(\n",
    "    filename,\n",
    "    pts_mat,\n",
    "    direction=\"LPS\",\n",
    "    pt_orientation=[0, 0, 0, 1],\n",
    "    pt_visibility=1,\n",
    "    pt_selected=0,\n",
    "    pt_locked=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save fCSV file that is slicer readable.\n",
    "    \"\"\"\n",
    "    # Create output file\n",
    "    OutObj = open(filename, \"w+\")\n",
    "\n",
    "    header0 = \"# Markups fiducial file version = 4.11\\n\"\n",
    "    header1 = \"# CoordinateSystem = \" + direction + \"\\n\"\n",
    "    header2 = \"# columns = id,x,y,z,ow,ox,oy,oz,vis,sel,lock,label,desc,associatedNodeID\\n\"\n",
    "\n",
    "    OutObj.writelines([header0, header1, header2])\n",
    "\n",
    "    outlines = []\n",
    "    for ii in range(pts_mat.shape[0]):\n",
    "        outlines.append(\n",
    "            str(ii + 1)\n",
    "            + \",\"\n",
    "            + str(pts_mat[ii, 0])\n",
    "            + \",\"\n",
    "            + str(pts_mat[ii, 1])\n",
    "            + \",\"\n",
    "            + str(pts_mat[ii, 2])\n",
    "            + f\",{pt_orientation[0]},{pt_orientation[1]},{pt_orientation[2]},{pt_orientation[3]},\"\n",
    "            + f\"{pt_visibility},{pt_selected},{pt_locked},\"\n",
    "            + str(ii)\n",
    "            + \",,vtkMRMLScalarVolumeNode1\\n\"\n",
    "        )\n",
    "\n",
    "    OutObj.writelines(outlines)\n",
    "    OutObj.close()\n",
    "\n",
    "\n",
    "def probe_df_to_fcsv(probe_data, extrema, results_folder, offset=(0, 0, 0)):\n",
    "    unq = np.unique(probe_data.tree_id)\n",
    "    probes = {}\n",
    "    for ii, uu in enumerate(unq):\n",
    "        this_probe_data = probe_data[probe_data.tree_id == uu]\n",
    "        x = extrema[0] - (this_probe_data.x / 1000).values + offset[0]\n",
    "        y = (this_probe_data.y / 1000).values + offset[1]\n",
    "        z = -(this_probe_data.z / 1000).values + offset[2]\n",
    "        probes[str(uu)] = np.vstack([x, y, z]).T\n",
    "        create_slicer_fcsv(\n",
    "            os.path.join(results_folder, f\"test{uu}.fcsv\"),\n",
    "            probes[str(uu)],\n",
    "            direction=\"LPS\",\n",
    "        )\n",
    "\n",
    "    return probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa55c02-f4ed-47c0-9e99-ffa012379958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotation_file_path = \"/data/713506_annotations\"\n",
    "annoation_manifest_path = \"/data/713506_test.csv\"\n",
    "registration_data_asset = \"/data/713506_to_ccf_Ex_639_Em_667_all_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac020e0f-7d6e-497e-9111-9ff86d6fa920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouseid</th>\n",
       "      <th>sorted_recording</th>\n",
       "      <th>surface_finding</th>\n",
       "      <th>probe_name</th>\n",
       "      <th>probe_file</th>\n",
       "      <th>probe_id</th>\n",
       "      <th>annotation_format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46802</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46116</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46110</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45882</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45883</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46117</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-13_13-21-59_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46108</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45882</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46116</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46110</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46802</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45883</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46117</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>713506</td>\n",
       "      <td>ecephys_713506_2024-02-21_14-55-09_sorted_2024...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46108</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>swc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mouseid                                   sorted_recording  \\\n",
       "0    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "1    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "2    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "3    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "4    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "5    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "6    713506  ecephys_713506_2024-02-13_13-21-59_sorted_2024...   \n",
       "7    713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "8    713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "9    713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "10   713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "11   713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "12   713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "13   713506  ecephys_713506_2024-02-21_14-55-09_sorted_2024...   \n",
       "\n",
       "    surface_finding  probe_name  probe_file  probe_id annotation_format  \n",
       "0               NaN       46802         203         0               swc  \n",
       "1               NaN       46116         204         0               swc  \n",
       "2               NaN       46110         205         0               swc  \n",
       "3               NaN       45882         206         0               swc  \n",
       "4               NaN       45883         207         0               swc  \n",
       "5               NaN       46117         208         0               swc  \n",
       "6               NaN       46108         209         0               swc  \n",
       "7               NaN       45882         210         0               swc  \n",
       "8               NaN       46116         211         0               swc  \n",
       "9               NaN       46110         212         0               swc  \n",
       "10              NaN       46802         213         0               swc  \n",
       "11              NaN       45883         214         0               swc  \n",
       "12              NaN       46117         215         0               swc  \n",
       "13              NaN       46108         216         0               swc  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(annoation_manifest_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79183cb2-f254-4637-afa7-27100c839030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the template and the ccf\n",
    "template = ants.image_read(\n",
    "    \"/data/smartspim_lca_template/smartspim_lca_template_25.nii.gz\"\n",
    ")\n",
    "ccf_25 = ants.image_read(\n",
    "    \"/data/allen_mouse_ccf/average_template/average_template_25.nii.gz\"\n",
    ")\n",
    "ccf_annotation_25 = ants.image_read(\n",
    "    \"/data/allen_mouse_ccf/annotation/ccf_2017/annotation_25.nii.gz\"\n",
    ")\n",
    "brain_atlas = atlas.AllenAtlas(25, hist_path=\"/scratch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ecc774-4c25-4c90-8291-918a9ec9edbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get volume information to interpret probe tracks\n",
    "zarr_read = ants.image_read(\n",
    "    os.path.join(registration_data_asset, \"registration\", \"prep_n4bias.nii.gz\")\n",
    ")\n",
    "extrema = np.array(zarr_read.shape) * np.array(zarr_read.spacing)\n",
    "offset = zarr_read.origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb36952-cb64-4015-88d6-8469ce2501f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get CCF space histology for this mouse\n",
    "histology_results = os.path.join(\n",
    "    \"/results\", str(df.mouseid[0]), \"ccf_space_histology\"\n",
    ")\n",
    "os.makedirs(histology_results, exist_ok=True)\n",
    "\n",
    "outimg = ants.image_read(\n",
    "    os.path.join(\n",
    "        registration_data_asset, \"registration\", \"moved_ls_to_ccf.nii.gz\"\n",
    "    )\n",
    ")\n",
    "ants.image_write(\n",
    "    outimg, os.path.join(histology_results, f\"histology_registration.nrrd\")\n",
    ")\n",
    "\n",
    "other_files = [\n",
    "    x\n",
    "    for x in os.listdir(os.path.join(registration_data_asset, \"registration\"))\n",
    "    if \"moved_ls_to_template_\" in x and \".nii.gz\" in x\n",
    "]\n",
    "for fl in other_files:\n",
    "    chname = fl.split(\"moved_ls_to_template_\")[-1].split(\".nii.gz\")[0]\n",
    "    image_in_template = ants.image_read(\n",
    "        os.path.join(registration_data_asset, \"registration\", fl)\n",
    "    )\n",
    "    outimg = ants.apply_transforms(\n",
    "        ccf_25,\n",
    "        image_in_template,\n",
    "        [\n",
    "            \"/data/spim_template_to_ccf/syn_1Warp.nii.gz\",\n",
    "            \"/data/spim_template_to_ccf/syn_0GenericAffine.mat\",\n",
    "        ],\n",
    "    )\n",
    "    ants.image_write(\n",
    "        outimg, os.path.join(histology_results, f\"histology_{chname}.nrrd\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ae097b-d5f9-4aef-a326-bd29069ff51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "track_results = Path(\"/results/\") / str(df.mouseid[0]) / \"track_data\"\n",
    "os.makedirs(track_results, exist_ok=True)\n",
    "spim_results = os.path.join(track_results, \"spim\")\n",
    "os.makedirs(spim_results, exist_ok=True)\n",
    "template_results = os.path.join(track_results, \"template\")\n",
    "os.makedirs(template_results, exist_ok=True)\n",
    "ccf_results = os.path.join(track_results, \"ccf\")\n",
    "os.makedirs(ccf_results, exist_ok=True)\n",
    "bregma_results = os.path.join(track_results, \"bregma_xyz\")\n",
    "os.makedirs(bregma_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc663ba5-0922-4807-96d7-ceb49926b26d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "Have not yet processed: ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38. Doing that now.\n",
      "Record Node 101#Neuropix-PXI-100.46108\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 101#Neuropix-PXI-100.46116\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 101#Neuropix-PXI-100.46802\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 108#Neuropix-PXI-100.45882\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 108#Neuropix-PXI-100.45883\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 108#Neuropix-PXI-100.46110\n",
      "Loading waveforms...\n",
      "Exporting to phy format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /scratch/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38_phy/params.py\n",
      "Converting data...\n",
      "Record Node 101#Neuropix-PXI-100.46108\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 101#Neuropix-PXI-100.46108_recording1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/spikeinterface/core/base.py:1038: UserWarning:\n",
      "\n",
      "Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.100.0 is recommended\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:02,  1.39it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Node 101#Neuropix-PXI-100.46116\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 101#Neuropix-PXI-100.46116_recording1\n",
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:06,  1.36it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Node 101#Neuropix-PXI-100.46802\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 101#Neuropix-PXI-100.46802_recording1\n",
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:07,  1.35it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Node 108#Neuropix-PXI-100.45882\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 108#Neuropix-PXI-100.45882_recording1\n",
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:06,  1.36it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Node 108#Neuropix-PXI-100.45883\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 108#Neuropix-PXI-100.45883_recording1\n",
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:07,  1.35it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Node 108#Neuropix-PXI-100.46110\n",
      "/data/ecephys_713506_2024-02-13_13-21-59_sorted_2024-02-14_08-03-38/postprocessed/experiment1_Record Node 108#Neuropix-PXI-100.46110_recording1\n",
      "Stream sample rate: 30000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [03:09,  1.33it/s]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "205\n",
      "Failed to find /data/713506_annotations/206.swc\n",
      "207\n",
      "Failed to find /data/713506_annotations/208.swc\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/results/713506/ecephys_713506_2024-02-13_13-21-59/46117/xyz_picks.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 72\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(bregma_results,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobe_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Serialize data to JSON format and write to file\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(xyz_picks, f)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxyz_picks.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     73\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(xyz_picks, f)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/results/713506/ecephys_713506_2024-02-13_13-21-59/46117/xyz_picks.json'"
     ]
    }
   ],
   "source": [
    "processed_recordings = []\n",
    "\n",
    "for ii, row in df.iterrows():\n",
    "    if row.annotation_format.lower() == \"swc\":\n",
    "        extension = \"swc\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Currently only swc annotations from horta are supported!\"\n",
    "        )\n",
    "\n",
    "    recording_id = row.sorted_recording.split(\"_sorted\")[0]\n",
    "    recording_folder = Path(\"/data/\") / row.sorted_recording\n",
    "    results_folder = Path(\"/results/\") / str(row.mouseid) / recording_id\n",
    "\n",
    "    if not os.path.exists(\n",
    "        Path(annotation_file_path) / f\"{row.probe_file}.{extension}\"\n",
    "    ):\n",
    "        missing = Path(annotation_file_path) / f\"{row.probe_file}.{extension}\"\n",
    "        print(f\"Failed to find {missing}\")\n",
    "        continue\n",
    "    else:\n",
    "        print(row.probe_file)\n",
    "        probe_data = import_swc_probe_data(\n",
    "            Path(annotation_file_path) / f\"{row.probe_file}.{extension}\"\n",
    "        )\n",
    "\n",
    "    # do the preprocessing for all channels in the given recording\n",
    "    # Any errors here are likely due files not being found.\n",
    "    # Check that the correct data are attached to the capsual!\n",
    "    if row.sorted_recording not in processed_recordings:\n",
    "        print(\n",
    "            f\"Have not yet processed: {row.sorted_recording}. Doing that now.\"\n",
    "        )\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "        extract_spikes(recording_folder, results_folder)\n",
    "        extract_continuous(recording_folder, results_folder)\n",
    "        processed_recordings.append(row.sorted_recording)\n",
    "\n",
    "    # Get relevent subset of data. Usefule if more than one probe in file...but we may cut this later.\n",
    "    this_probe_data = probe_data[probe_data.tree_id == row.probe_id]\n",
    "    if np.any(probe_data.tree_id.values > 0):\n",
    "        probe_name = row.probe_file + \"_\" + row.probe_id\n",
    "    else:\n",
    "        probe_name = row.probe_file\n",
    "\n",
    "    # Get probe in spim space.\n",
    "    # This math handles different readout conventions.\n",
    "    x = extrema[0] - (this_probe_data.x / 1000).values + offset[0]\n",
    "    y = (this_probe_data.y / 1000).values + offset[1]\n",
    "    z = -(this_probe_data.z / 1000).values + offset[2]\n",
    "    this_probe = np.vstack([x, y, z]).T\n",
    "    create_slicer_fcsv(\n",
    "        os.path.join(spim_results, f\"{probe_name}.fcsv\"),\n",
    "        this_probe,\n",
    "        direction=\"LPS\",\n",
    "    )\n",
    "\n",
    "    # Move probe into template space.\n",
    "    this_probe_df = pd.DataFrame(\n",
    "        {\"x\": this_probe[:, 0], \"y\": this_probe[:, 1], \"z\": this_probe[:, 2]}\n",
    "    )\n",
    "    # Transform into template space\n",
    "    this_probe_template = ants.apply_transforms_to_points(\n",
    "        3,\n",
    "        this_probe_df,\n",
    "        [\n",
    "            os.path.join(\n",
    "                registration_data_asset,\n",
    "                \"registration\",\n",
    "                \"ls_to_template_SyN_0GenericAffine.mat\",\n",
    "            ),\n",
    "            os.path.join(\n",
    "                registration_data_asset,\n",
    "                \"registration\",\n",
    "                \"ls_to_template_SyN_1InverseWarp.nii.gz\",\n",
    "            ),\n",
    "        ],\n",
    "        whichtoinvert=[True, False],\n",
    "    )\n",
    "    create_slicer_fcsv(\n",
    "        os.path.join(template_results, f\"{probe_name}.fcsv\"),\n",
    "        this_probe_template.values,\n",
    "        direction=\"LPS\",\n",
    "    )\n",
    "\n",
    "    # Move probe into ccf space\n",
    "    this_probe_ccf = ants.apply_transforms_to_points(\n",
    "        3,\n",
    "        this_probe_template,\n",
    "        [\n",
    "            \"/data/spim_template_to_ccf/syn_0GenericAffine.mat\",\n",
    "            \"/data/spim_template_to_ccf/syn_1InverseWarp.nii.gz\",\n",
    "        ],\n",
    "        whichtoinvert=[True, False],\n",
    "    )\n",
    "    create_slicer_fcsv(\n",
    "        os.path.join(ccf_results, f\"{probe_name}.fcsv\"),\n",
    "        this_probe_ccf.values,\n",
    "        direction=\"LPS\",\n",
    "    )\n",
    "\n",
    "    # Transform into ibl x-y-z-picks space\n",
    "    ccf_mlapdv = this_probe_ccf.values.copy() * 1000\n",
    "    ccf_mlapdv[:, 0] = -ccf_mlapdv[:, 0]\n",
    "    ccf_mlapdv[:, 1] = ccf_mlapdv[:, 1]\n",
    "    ccf_mlapdv[:, 2] = -ccf_mlapdv[:, 2]\n",
    "    bregma_mlapdv = (\n",
    "        brain_atlas.ccf2xyz(ccf_mlapdv, ccf_order=\"mlapdv\") * 1000000\n",
    "    )\n",
    "    xyz_picks = {\"xyz_picks\": bregma_mlapdv.tolist()}\n",
    "\n",
    "    # Save this in two locations. First, save sorted by filename\n",
    "    with open(os.path.join(bregma_results, f\"{probe_name}.json\"), \"w\") as f:\n",
    "        # Serialize data to JSON format and write to file\n",
    "        json.dump(xyz_picks, f)\n",
    "\n",
    "    with open(\n",
    "        os.path.join(results_folder, str(row.probe_name), \"xyz_picks.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(xyz_picks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5b14e-8575-4e4b-85bc-74af9f5d1d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
